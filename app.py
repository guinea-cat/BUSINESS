"""
app.py
Gradio Web ç•Œé¢æ¼”ç¤ºã€‚
"""

import gradio as gr
import config
import logging
from agent import BusinessResearcher

# åˆå§‹åŒ–æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def run_analysis(file_obj):
    """
    å¤„ç†ä¸Šä¼ æ–‡ä»¶å¹¶è°ƒç”¨åˆ†ææµæ°´çº¿ã€‚
    """
    if file_obj is None:
        return "# âš ï¸ è¯·å…ˆä¸Šä¼  PDF æ–‡ä»¶", {}
    
    try:
        pdf_path = file_obj.name
        researcher = BusinessResearcher(config.LLM_API_KEY)
        
        # è°ƒç”¨æ ¸å¿ƒæµæ°´çº¿æ–¹æ³•
        result = researcher.analyze_bp_pipeline(pdf_path)
        
        # æ ¼å¼åŒ– Markdown æŠ¥å‘Š
        markdown_report = format_markdown(result)
        return markdown_report, result
        
    except Exception as e:
        logger.error(f"UI å¤„ç†å¼‚å¸¸: {e}")
        return f"# âŒ ç³»ç»Ÿå¤„ç†å¼‚å¸¸\n{str(e)}", {"status": "error"}

def format_markdown(data: dict) -> str:
    """
    å°†åˆ†æç»“æœ JSON è½¬æ¢ä¸º Markdown ç ”æŠ¥ã€‚
    """
    from datetime import datetime
    import re
    
    if "error" in data:
        return f"# âš ï¸ é”™è¯¯\n\n{data.get('error')}\n\n**è¯¦ç»†ä¿¡æ¯**: {data.get('details', 'N/A')}"
    
    # è¾…åŠ©å‡½æ•°ï¼šå°† [S1] è½¬æ¢ä¸ºä¸Šæ ‡æ ¼å¼
    def cite_repl(match):
        return f"<sup>{match.group(0)}</sup>"
    
    def process_citations(text: str) -> str:
        if not isinstance(text, str): return str(text)
        return re.sub(r"\[S\d+\]", cite_repl, text)

    md = "# ğŸ“Š ç§‘åˆ›å¤§èµ› AI è¯„å®¡ - æ·±åº¦å•†ä¸šåˆ†ææŠ¥å‘Š\n\n---\n\n"
    
    # 1. é¡¹ç›®æ·±åº¦ç”»åƒ
    pi = data.get("project_identity", {})
    md += f"## ğŸš€ é¡¹ç›®æœ¬ä½“ç”»åƒ (Project Identity)\n"
    md += f"**é¡¹ç›®åç§°**: {pi.get('project_name', 'N/A')}\n\n"
    md += f"**æ ¸å¿ƒæ„¿æ™¯**: *{pi.get('slogan', 'N/A')}*\n\n"
    md += f"### ğŸ“ æ·±åº¦æè¿°\n{process_citations(pi.get('description', 'N/A'))}\n\n"
    md += f"### ğŸ’° ç›ˆåˆ©æ¨¡å¼\n{process_citations(pi.get('revenue_model', 'N/A'))}\n\n"
    md += f"### ğŸ‘¥ å›¢é˜ŸèƒŒæ™¯ä¼˜åŠ¿\n{process_citations(pi.get('team_background', 'N/A'))}\n\n"
    md += f"- **å‘å±•é˜¶æ®µ**: `{pi.get('stage', 'N/A')}`\n\n"
    
    # 2. èµ›é“ä¸å¸‚åœº
    ia = data.get("industry_analysis", {})
    md += "## ğŸŒ èµ›é“åˆ†æä¸å¸‚åœºé‡åŒ–\n"
    md += f"- **è¯†åˆ«èµ›é“**: {ia.get('detected_industry', 'N/A')}\n"
    md += f"- **å¸‚åœºè§„æ¨¡**: {process_citations(ia.get('market_size', 'Not Found'))}\n"
    md += f"- **å¤åˆå¢é•¿ç‡ (CAGR)**: {process_citations(ia.get('cagr', 'Not Found'))}\n"
    md += f"- **æ•°æ®æ¥æº**: {ia.get('source', 'N/A')}\n\n"

    # 3. å•†ä¸šæ·±åº¦æ‹†è§£
    ba = data.get("business_analysis", {})
    md += "## âš–ï¸ å•†ä¸šæ·±åº¦æ‹†è§£\n"
    md += f"### ğŸ¢ å•†ä¸šæ¨¡å¼å¯è¡Œæ€§è¯„è¿°\n{process_citations(ba.get('business_model_critique', 'N/A'))}\n\n"
    md += f"### ğŸ›¡ï¸ æŠ€æœ¯å£å’ä¸æŠ¤åŸæ²³\n{process_citations(ba.get('technical_moat', 'N/A'))}\n\n"
    
    # 4. VC çµé­‚æ‹·é—® (æ–°æ¨¡å—)
    vg = data.get("vc_grill", [])
    if vg:
        md += "## ğŸ”¥ VC çµé­‚æ‹·é—® (The VC Grill)\n"
        for item in vg:
            md += f"**Q: {item.get('question')}**\n\n"
            md += f"**A:** {process_citations(item.get('answer'))}\n\n"
    
    # 5. ç«å“
    md += "## ğŸ¯ ç«äº‰æ ¼å±€ä¸æ›¿ä»£å“\n"
    for comp in data.get("competitors", []):
        md += f"### ğŸ¢ {comp.get('name')}\n- **ç±»å‹**: {comp.get('type')}\n- **åˆ†æ**: {process_citations(comp.get('comparison'))}\n\n"
    
    # 6. èèµ„ä¸èˆ†æƒ…
    fe = data.get("funding_ecosystem", {})
    ps = data.get("public_sentiment", {})
    md += f"## ğŸ’¹ èèµ„ç”Ÿæ€ & èˆ†æƒ…ç ”åˆ¤\n"
    md += f"- **èµ„æœ¬çƒ­åº¦**: `{fe.get('heat_level', 'N/A')}`\n"
    md += f"- **åŠ¨æ€æ‘˜è¦**: {process_citations(fe.get('trend_summary', 'N/A'))}\n"
    md += f"- **èˆ†æƒ…å€¾å‘**: {ps.get('label')} â€” {process_citations(ps.get('summary'))}\n\n"
    
    # 7. é£é™©
    md += "## âš ï¸ æ ¸å¿ƒé£é™©è¯†åˆ«\n"
    for risk in data.get("risk_assessment", []):
        md += f"- {process_citations(risk)}\n"
    
    # 8. æ•°æ®æ¥æºä¸å‚è€ƒæ–‡çŒ®
    md += "\n---\n## ğŸ”— æ•°æ®æ¥æºä¸å‚è€ƒæ–‡çŒ®\n"
    evidence = data.get("raw_evidence", [])
    if evidence:
        for item in evidence:
            eid = item.get('id', 'N/A')
            md += f"- **[{eid}] {item.get('source')}**: [{item.get('url')}]({item.get('url')})\n"
    else:
        md += "- æš‚æ— å¤–éƒ¨å‚è€ƒé“¾æ¥ã€‚\n"
    
    md += f"\n---\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
    return md

def main():
    with gr.Blocks(title="SAGE Business Analysis", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸš€ SAGE å•†ä¸šæ½œåŠ› AI è¯„æµ‹ç³»ç»Ÿ\nåŸºäº DeepSeek & Serper.dev çš„å…¨è¡Œä¸šé€šç”¨åˆ†æå¼•æ“ã€‚")
        
        with gr.Row():
            with gr.Column(scale=1):
                pdf_input = gr.File(label="ä¸Šä¼  BP (PDF)", file_types=[".pdf"])
                btn = gr.Button("å¼€å§‹å…¨è‡ªåŠ¨åˆ†æ", variant="primary")
                gr.Markdown("### âš™ï¸ è¯´æ˜\n- ç³»ç»Ÿå°†è‡ªåŠ¨è¯†åˆ«èµ›é“å¹¶è¿›è¡Œå…¨ç½‘æƒ…æŠ¥æ£€ç´¢ã€‚\n- åˆ†æè€—æ—¶é¢„è®¡ 45-60 ç§’ã€‚")
                
            with gr.Column(scale=2):
                with gr.Tabs():
                    with gr.Tab("ğŸ“ ç ”æŠ¥è§†å›¾"):
                        out_md = gr.Markdown("ç­‰å¾…åˆ†æ...")
                    with gr.Tab("ğŸ“Š åŸå§‹æ•°æ®"):
                        out_json = gr.JSON()
        
        btn.click(fn=run_analysis, inputs=pdf_input, outputs=[out_md, out_json])
    
    demo.launch(server_port=8081, inbrowser=True)

if __name__ == "__main__":
    main()
