"""
app.py
Gradio Web ç•Œé¢æ¼”ç¤ºã€‚
"""

import gradio as gr
import config
import logging
import time
from agent import BusinessResearcher

# åˆå§‹åŒ–æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def run_analysis(file_obj):
    """
    å¤„ç†ä¸Šä¼ æ–‡ä»¶å¹¶è°ƒç”¨åˆ†ææµæ°´çº¿ã€‚
    ä½¿ç”¨ yield æœºåˆ¶å®æ—¶è¿”å›è¿›åº¦çŠ¶æ€ï¼ˆä¼˜åŒ–ç”¨æˆ·ä½“éªŒï¼‰ã€‚
    """
    if file_obj is None:
        yield "# âš ï¸ è¯·å…ˆä¸Šä¼  PDF æ–‡ä»¶", {}
        return
    
    try:
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        pdf_path = file_obj.name
        researcher = BusinessResearcher(config.LLM_API_KEY)
        
        # é˜¶æ®µ 1ï¼šPDF è§£æ
        elapsed = time.time() - start_time
        yield f"## ğŸ“„ æ­£åœ¨è§£æ PDF ä¸å›¾ç‰‡... (å·²è€—æ—¶ {elapsed:.1f}s)\n\nè¯·ç¨å€™ï¼Œç³»ç»Ÿæ­£åœ¨æå–æ–‡æœ¬å†…å®¹å’Œè§†è§‰å…ƒç´ ã€‚", {}
        
        import utils
        pdf_content = utils.extract_content_from_pdf(pdf_path)
        bp_full_text = pdf_content["text"]
        bp_images = pdf_content["images"]
        
        # é˜¶æ®µ 2ï¼šè§†è§‰åˆ†æ
        if bp_images:
            elapsed = time.time() - start_time
            yield f"## ğŸ–¼ï¸ æ­£åœ¨å¹¶å‘è§†è§‰åˆ†æ... (å·²è€—æ—¶ {elapsed:.1f}s)\n\næ£€æµ‹åˆ° {len(bp_images)} å¼ å›¾ç‰‡ï¼Œæ­£åœ¨è¿›è¡Œ 2x2 æ‹¼å›¾ä¸å¹¶å‘åˆ†æã€‚", {}
            visual_descriptions = utils.describe_visual_elements(researcher.vision_client, bp_images)
        else:
            visual_descriptions = ""
        
        # é˜¶æ®µ 3ï¼šèµ›é“è¯†åˆ«
        enhanced_text = bp_full_text
        if visual_descriptions and visual_descriptions != "æœªå‘ç°æ˜¾è‘—è§†è§‰å…ƒç´ ã€‚":
            enhanced_text = f"{bp_full_text}\n\n{visual_descriptions}"
        
        elapsed = time.time() - start_time
        yield f"## ğŸ¯ æ­£åœ¨è¯†åˆ«é¡¹ç›®èµ›é“... (å·²è€—æ—¶ {elapsed:.1f}s)\n\nåŸºäº BP å†…å®¹è¿›è¡Œèµ›é“åˆ†ç±»ã€‚", {}
        detected_industry = researcher._detect_industry(enhanced_text)
        
        # é˜¶æ®µ 4ï¼šå¹¶å‘æœç´¢
        elapsed = time.time() - start_time
        yield f"## ğŸ” æ­£åœ¨å…¨ç½‘æœç´¢... (å·²è€—æ—¶ {elapsed:.1f}s)\n\nèµ›é“ï¼š**{detected_industry}**\n\næ­£åœ¨å¹¶å‘æœç´¢ 10 ä¸ªå…³é”®è¯ï¼Œè·å–å¸‚åœºæ•°æ®ã€ç«å“ä¿¡æ¯å’Œèèµ„åŠ¨æ€ã€‚", {}
        keywords = researcher._get_search_keywords(enhanced_text, detected_industry)
        search_results = researcher._concurrent_search(keywords)
        
        # é˜¶æ®µ 5ï¼šå¹¶å‘ JSON ç”Ÿæˆ
        elapsed = time.time() - start_time
        yield f"## ğŸ§  æ­£åœ¨ç”Ÿæˆæœ€ç»ˆç ”æŠ¥... (å·²è€—æ—¶ {elapsed:.1f}s)\n\nå¹¶å‘æ‰§è¡Œ **4 è·¯å¹¶å‘åˆ†æ**ï¼š\n- åŸºç¡€ä¿¡æ¯ç»„ï¼ˆé¡¹ç›®ç”»åƒ + èµ›é“åˆ†æï¼‰\n- å¤–éƒ¨æƒ…æŠ¥ç»„ï¼ˆç«å“ + èèµ„ç”Ÿæ€ï¼‰\n- **ä¼°å€¼æ¨¡å‹ç»„**ï¼ˆVC è¯„åˆ†ï¼‰\n- **é£é™©è¯„ä¼°ç»„**ï¼ˆæ‹·é—® + ç—›ç‚¹ + é£é™©ï¼‰", {}
        
        # è°ƒç”¨å®Œæ•´çš„åˆ†ææµæ°´çº¿
        result = researcher.analyze_bp_pipeline(pdf_path)
        
        # è®¡ç®—æ€»è€—æ—¶
        total_time = time.time() - start_time
        
        # æ ¼å¼åŒ– Markdown æŠ¥å‘Šï¼ˆåŒ…å«æ€»è€—æ—¶ï¼‰
        markdown_report = format_markdown(result, total_time)
        yield markdown_report, result
        
    except Exception as e:
        logger.error(f"UI å¤„ç†å¼‚å¸¸: {e}")
        yield f"# âŒ ç³»ç»Ÿå¤„ç†å¼‚å¸¸\n{str(e)}", {"status": "error"}

def format_markdown(data: dict, total_time: float = 0) -> str:
    """
    å°†åˆ†æç»“æœ JSON è½¬æ¢ä¸º Markdown ç ”æŠ¥ã€‚
    
    å‚æ•°:
        data: åˆ†æç»“æœå­—å…¸
        total_time: æ€»è€—æ—¶ï¼ˆç§’ï¼‰
    """
    from datetime import datetime
    import re
    
    if "error" in data:
        return f"# âš ï¸ é”™è¯¯\n\n{data.get('error')}\n\n**è¯¦ç»†ä¿¡æ¯**: {data.get('details', 'N/A')}"
    
    # è¾…åŠ©å‡½æ•°ï¼šå°† [S1] è½¬æ¢ä¸ºä¸Šæ ‡æ ¼å¼
    def cite_repl(match):
        return f"<sup>{match.group(0)}</sup>"
    
    def process_citations(text: str) -> str:
        if not isinstance(text, str): return str(text)
        return re.sub(r"\[S\d+\]", cite_repl, text)

    md = "# ğŸ“Š ç§‘åˆ›å¤§èµ› AI è¯„å®¡ - æ·±åº¦å•†ä¸šåˆ†ææŠ¥å‘Š\n\n---\n\n"
    
    # 1. é¡¹ç›®æ·±åº¦ç”»åƒ
    pi = data.get("project_identity", {})
    md += f"## ğŸš€ é¡¹ç›®æœ¬ä½“ç”»åƒ (Project Identity)\n"
    md += f"**é¡¹ç›®åç§°**: {pi.get('project_name', 'N/A')}\n\n"
    md += f"**æ ¸å¿ƒæ„¿æ™¯**: *{pi.get('slogan', 'N/A')}*\n\n"
    md += f"### ğŸ“ æ·±åº¦æè¿°\n{process_citations(pi.get('description', 'N/A'))}\n\n"
    md += f"### ğŸ’° ç›ˆåˆ©æ¨¡å¼\n{process_citations(pi.get('revenue_model', 'N/A'))}\n\n"
    md += f"### ğŸ‘¥ å›¢é˜ŸèƒŒæ™¯ä¼˜åŠ¿\n{process_citations(pi.get('team_background', 'N/A'))}\n\n"
    md += f"- **å‘å±•é˜¶æ®µ**: `{pi.get('stage', 'N/A')}`\n\n"
    
    # 2. èµ›é“ä¸å¸‚åœº
    ia = data.get("industry_analysis", {})
    md += "## ğŸŒ èµ›é“åˆ†æä¸å¸‚åœºé‡åŒ–\n"
    md += f"- **è¯†åˆ«èµ›é“**: {ia.get('detected_industry', 'N/A')}\n"
    md += f"- **å¸‚åœºè§„æ¨¡**: {process_citations(ia.get('market_size', 'Not Found'))}\n"
    md += f"- **å¤åˆå¢é•¿ç‡ (CAGR)**: {process_citations(ia.get('cagr', 'Not Found'))}\n"
    md += f"- **æ•°æ®æ¥æº**: {ia.get('source', 'N/A')}\n\n"

    # 3. å•†ä¸šæ·±åº¦æ‹†è§£
    ba = data.get("business_analysis", {})
    md += "## âš–ï¸ å•†ä¸šæ·±åº¦æ‹†è§£\n"
    md += f"### ğŸ¢ å•†ä¸šæ¨¡å¼å¯è¡Œæ€§è¯„è¿°\n{process_citations(ba.get('business_model_critique', 'N/A'))}\n\n"
    md += f"### ğŸ›¡ï¸ æŠ€æœ¯å£å’ä¸æŠ¤åŸæ²³\n{process_citations(ba.get('technical_moat', 'N/A'))}\n\n"
    
    # 4. VC çµé­‚æ‹·é—® (æ–°æ¨¡å—)
    vg = data.get("vc_grill", [])
    if vg:
        md += "## ğŸ”¥ VC çµé­‚æ‹·é—® (The VC Grill)\n"
        for item in vg:
            md += f"**Q: {item.get('question')}**\n\n"
            md += f"**A:** {process_citations(item.get('answer'))}\n\n"
    
    # 5. ç«å“
    md += "## ğŸ¯ ç«äº‰æ ¼å±€ä¸æ›¿ä»£å“\n"
    for comp in data.get("competitors", []):
        md += f"### ğŸ¢ {comp.get('name')}\n- **ç±»å‹**: {comp.get('type')}\n- **åˆ†æ**: {process_citations(comp.get('comparison'))}\n\n"
    
    # 6. èèµ„ä¸èˆ†æƒ…
    fe = data.get("funding_ecosystem", {})
    ps = data.get("public_sentiment", {})
    md += f"## ğŸ’¹ èèµ„ç”Ÿæ€ & èˆ†æƒ…ç ”åˆ¤\n"
    md += f"- **èµ„æœ¬çƒ­åº¦**: `{fe.get('heat_level', 'N/A')}`\n"
    md += f"- **åŠ¨æ€æ‘˜è¦**: {process_citations(fe.get('trend_summary', 'N/A'))}\n"
    md += f"- **èˆ†æƒ…å€¾å‘**: {ps.get('label')} â€” {process_citations(ps.get('summary'))}\n\n"
    
    # 7. é£é™©
    md += "## âš ï¸ æ ¸å¿ƒé£é™©è¯†åˆ«\n"
    for risk in data.get("risk_assessment", []):
        md += f"- {process_citations(risk)}\n"
    
    # 8. æ•°æ®æ¥æºä¸å‚è€ƒæ–‡çŒ®
    md += "\n---\n## ğŸ”— æ•°æ®æ¥æºä¸å‚è€ƒæ–‡çŒ®\n"
    evidence = data.get("raw_evidence", [])
    if evidence:
        for item in evidence:
            eid = item.get('id', 'N/A')
            md += f"- **[{eid}] {item.get('source')}**: [{item.get('url')}]({item.get('url')})\n"
    else:
        md += "- æš‚æ— å¤–éƒ¨å‚è€ƒé“¾æ¥ã€‚\n"
    
    md += f"\n---\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n\n"
    md += f"*æœ¬æ¬¡åˆ†ææ€»è€—æ—¶: {total_time:.1f} ç§’*"
    return md

def main():
    with gr.Blocks(title="SAGE Business Analysis", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸš€ SAGE å•†ä¸šæ½œåŠ› AI è¯„æµ‹ç³»ç»Ÿ\nåŸºäº DeepSeek & Serper.dev çš„å…¨è¡Œä¸šé€šç”¨åˆ†æå¼•æ“ã€‚")
        
        with gr.Row():
            with gr.Column(scale=1):
                pdf_input = gr.File(label="ä¸Šä¼  BP (PDF)", file_types=[".pdf"])
                btn = gr.Button("å¼€å§‹å…¨è‡ªåŠ¨åˆ†æ", variant="primary")
                gr.Markdown("### âš™ï¸ è¯´æ˜\n- ç³»ç»Ÿå°†è‡ªåŠ¨è¯†åˆ«èµ›é“å¹¶è¿›è¡Œå…¨ç½‘æƒ…æŠ¥æ£€ç´¢ã€‚\n- åˆ†æè€—æ—¶é¢„è®¡ 45-60 ç§’ã€‚")
                
            with gr.Column(scale=2):
                with gr.Tabs():
                    with gr.Tab("ğŸ“ ç ”æŠ¥è§†å›¾"):
                        out_md = gr.Markdown("ç­‰å¾…åˆ†æ...")
                    with gr.Tab("ğŸ“Š åŸå§‹æ•°æ®"):
                        out_json = gr.JSON()
        
        btn.click(fn=run_analysis, inputs=pdf_input, outputs=[out_md, out_json], api_name=False)
    
    demo.launch(server_port=8081, inbrowser=True)

if __name__ == "__main__":
    main()
