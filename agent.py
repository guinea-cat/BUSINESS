"""
agent.py
å•†ä¸šåˆ†ææ™ºèƒ½ä½“æ ¸å¿ƒæ¨¡å—ã€‚
è´Ÿè´£åè°ƒ PDF è§£æã€èµ›é“è¯†åˆ«ã€è”ç½‘æœç´¢åŠå…¨é¢†åŸŸ VC è§†è§’æ·±åº¦åˆ†æã€‚
ä¼˜åŒ–ç‰ˆï¼šæœç´¢æ¨¡å—å¹¶å‘æ‰§è¡Œï¼Œå¤§å¹…ç¼©çŸ­æ€»ä½“åˆ†ææ—¶é—´ã€‚
"""

import json
import logging
import traceback
from typing import List, Dict
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed
import config
import utils

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class BusinessResearcher:
    """
    å•†ä¸šç ”ç©¶å‘˜æ™ºèƒ½ä½“ï¼Œæ¨¡æ‹Ÿ VC åˆä¼™äººè¿›è¡Œé¡¹ç›®è¯„å®¡ã€‚
    """

    def __init__(self, api_key: str):
        """
        åˆå§‹åŒ–æ™ºèƒ½ä½“ã€‚
        
        å‚æ•°:
            api_key (str): LLM æˆæƒå¯†é’¥ã€‚
        """
        self.api_key = api_key
        self.client = OpenAI(
            api_key=api_key,
            base_url=config.LLM_BASE_URL
        )
        
        # è§†è§‰ä¸“ç”¨å®¢æˆ·ç«¯ (è§£å†³ 400 é”™è¯¯ï¼šè§£è€¦å¤šæ¨¡æ€ä¸æ–‡æœ¬è¯·æ±‚)
        vision_api_key = getattr(config, "VISION_API_KEY", api_key)
        vision_base_url = getattr(config, "VISION_BASE_URL", config.LLM_BASE_URL)
        
        # å¦‚æœè§†è§‰é…ç½®ä¸æ–‡æœ¬é…ç½®ä¸€è‡´ä¸”ä¸º DeepSeekï¼Œåˆ™ä¼šæœ‰å…¼å®¹æ€§é£é™©
        # å»ºè®®ç”¨æˆ·åœ¨ config.py ä¸­æ˜ç¡®é…ç½® VISION_BASE_URL ä¸ºæ”¯æŒ Vision çš„ç«¯ç‚¹
        self.vision_client = OpenAI(
            api_key=vision_api_key,
            base_url=vision_base_url,
            timeout=120.0  # å¢åŠ è¶…æ—¶é™åˆ¶ï¼Œé€‚åº”ä»£ç†ç¯å¢ƒä¸‹çš„å›¾ç‰‡ä¸Šä¼ 
        )

    def _perceive_context(self, bp_text: str) -> Dict:
        """
        ã€æ€§èƒ½ä¼˜åŒ–ã€‘åˆå¹¶æ¨ç†é˜¶æ®µï¼šä¸€æ¬¡æ€§è¯†åˆ«èµ›é“ + ç”Ÿæˆæœç´¢å…³é”®è¯ã€‚
        
        åŸç†è§£æï¼š
        - åŸæµç¨‹ï¼š_detect_industry (LLM Call 1) â†’ _get_search_keywords (LLM Call 2)
        - ä¼˜åŒ–åï¼šå•æ¬¡ LLM Call åŒæ—¶å®Œæˆä¸¤é¡¹ä»»åŠ¡ï¼Œå‡å°‘ç½‘ç»œå¾€è¿”å»¶è¿Ÿ 2-3ç§’
        - Qwen-Plus çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›è¶³å¤Ÿå¼ºï¼Œèƒ½åœ¨ä¸€æ¬¡æ¨ç†ä¸­å®Œæˆå¤åˆä»»åŠ¡
        
        å‚æ•°:
            bp_text (str): BP å…¨æ–‡ï¼ˆå¯åŒ…å«å›¾è¡¨æè¿°çš„å¢å¼ºæ–‡æœ¬ï¼‰ã€‚
            
        è¿”å›:
            Dict: {"industry": "ç»†åˆ†èµ›é“åç§°", "keywords": ["å…³é”®è¯1", ...]}
        """
        bp_snippet = bp_text[:30000]  # ä½¿ç”¨æ›´é•¿çš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿ä¿¡æ¯å……åˆ†
        
        prompt = (
            "ä½ æ˜¯ä¸€åå…¨é¢†åŸŸ VC åˆä¼™äººï¼Œæ“…é•¿å¿«é€Ÿè¯†åˆ«åˆ›ä¸šé¡¹ç›®çš„ç»†åˆ†èµ›é“å¹¶æå–å…³é”®å•†ä¸šæƒ…æŠ¥ã€‚\n\n"
            "### ä»»åŠ¡ï¼ˆè¯·åŒæ—¶å®Œæˆä»¥ä¸‹ä¸¤é¡¹ï¼‰\n"
            "1. **è¯†åˆ«ç»†åˆ†èµ›é“**ï¼šåˆ¤æ–­è¯¥é¡¹ç›®å±äºå“ªä¸ªç»†åˆ†èµ›é“ï¼ˆæ ¼å¼ï¼š'å¤§èµ›é“ - å°èµ›é“'ï¼Œå¦‚ 'æ™ºæ…§åŒ»ç–— - AI è¾…åŠ©è¯Šæ–­'ï¼‰ã€‚\n"
            "2. **ç”Ÿæˆæœç´¢å…³é”®è¯**ï¼šæå– 10 ä¸ªç²¾å‡†çš„ä¸­è‹±æ–‡åŒè¯­æœç´¢å…³é”®è¯ï¼ˆ5 ä¸ªä¸­æ–‡ + 5 ä¸ªè‹±æ–‡ï¼‰ï¼Œç”¨äºåœ¨ Google æŸ¥æ‰¾ï¼š\n"
            "   - ä¸­æ–‡å…³é”®è¯ï¼šå›½å†…å¸‚åœºè§„æ¨¡ã€æ”¿ç­–ç¯å¢ƒã€æœ¬åœŸç«å“åˆ†æ\n"
            "   - è‹±æ–‡å…³é”®è¯ï¼šå…¨çƒè¡Œä¸šæŠ¥å‘Šï¼ˆGlobal Market Reportï¼‰ã€æµ·å¤–å·¨å¤´åŠ¨æ€ï¼ˆLeading Playersï¼‰ã€å›½é™…èèµ„è¶‹åŠ¿ï¼ˆFunding Trendsï¼‰\n"
            "   - å¿…é¡»åŒ…å«æ¨¡å¼å˜ä½“ï¼šå¦‚ '{Industry} market size'ã€'{Competitor} revenue'ã€'{Industry} failure cases'\n\n"
            "### è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»æ˜¯çº¯ JSONï¼Œä¸åŒ…å« Markdown æ ‡è®°ï¼‰\n"
            "{\n"
            '  "industry": "å¤§èµ›é“ - å°èµ›é“",\n'
            '  "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", ..., "å…³é”®è¯10"]\n'
            "}\n\n"
            f"å•†ä¸šè®¡åˆ’ä¹¦å†…å®¹ï¼š\n{bp_snippet}"
        )
        
        try:
            response = self.client.chat.completions.create(
                model=config.LLM_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3  # ä¿æŒé€‚åº¦åˆ›é€ æ€§ä»¥ç”Ÿæˆå¤šæ ·åŒ–å…³é”®è¯
            )
            raw_output = response.choices[0].message.content.strip()
            
            # JSON è§£æï¼ˆå¤ç”¨ utils ä¸­çš„æ¸…æ´—é€»è¾‘ï¼‰
            clean_json = utils.clean_json_string(raw_output)
            result = json.loads(clean_json)
            
            # æå–å­—æ®µ
            industry = result.get("industry", "å…¨é¢†åŸŸèµ›é“")
            keywords = result.get("keywords", [])
            
            # å…³é”®è¯å…œåº•é€»è¾‘ï¼ˆå‚è€ƒè®°å¿†ä¸­çš„å…œåº•æœºåˆ¶ï¼‰
            invalid_keywords = ['not found', 'unknown', 'none', 'error', 'project name']
            if not keywords or any(kw.lower() in invalid_keywords for kw in keywords):
                logger.warning(f"å…³é”®è¯ç”Ÿæˆæ— æ•ˆï¼Œè§¦å‘å…œåº•æœºåˆ¶ã€‚åŸå§‹å…³é”®è¯: {keywords}")
                keywords = [
                    f"{industry} å¸‚åœºè§„æ¨¡",
                    f"{industry} market size",
                    f"{industry} competitors",
                    f"{industry} å•†ä¸šæ¨¡å¼",
                    f"{industry} business model",
                    f"{industry} trends",
                    f"{industry} funding",
                    f"{industry} èèµ„åŠ¨æ€",
                    f"{industry} failure cases",
                    f"{industry} è¡Œä¸šæŠ¥å‘Š"
                ]
            
            logger.info(f"èµ›é“æ„ŸçŸ¥å®Œæˆ - èµ›é“: {industry}, ç”Ÿæˆå…³é”®è¯æ•°: {len(keywords)}")
            return {"industry": industry, "keywords": keywords[:10]}
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON è§£æå¤±è´¥: {e}ï¼ŒåŸå§‹è¾“å‡º: {raw_output[:200]}...")
            # å…œåº•ï¼šå°è¯•ä»çº¯æ–‡æœ¬ä¸­æå–
            return self._fallback_perceive_context(bp_text)
        except Exception as e:
            logger.error(f"èµ›é“æ„ŸçŸ¥å¤±è´¥: {e}")
            return self._fallback_perceive_context(bp_text)
    
    def _fallback_perceive_context(self, bp_text: str) -> Dict:
        """
        å…œåº•é€»è¾‘ï¼šå½“ JSON è§£æå¤±è´¥æ—¶ï¼Œä½¿ç”¨ä¿å®ˆçš„é»˜è®¤å€¼ã€‚
        
        åŸç†ï¼š
        - ä» BP æ–‡æœ¬ä¸­æå–é«˜é¢‘è¯ä½œä¸ºèµ›é“çº¿ç´¢
        - ç”Ÿæˆé€šç”¨æœç´¢å…³é”®è¯æ¨¡æ¿
        
        å‚æ•°:
            bp_text (str): BP å…¨æ–‡
            
        è¿”å›:
            Dict: {"industry": "å…¨é¢†åŸŸèµ›é“", "keywords": [...]}
        """
        logger.warning("ä½¿ç”¨å…œåº•é€»è¾‘ç”Ÿæˆèµ›é“å’Œå…³é”®è¯")
        
        # ç®€å•çš„èµ›é“æ¨æ–­ï¼ˆåŸºäºé«˜é¢‘å…³é”®è¯ï¼‰
        industry = "å…¨é¢†åŸŸèµ›é“"
        bp_lower = bp_text[:5000].lower()
        
        # å¸¸è§èµ›é“å…³é”®è¯æ˜ å°„
        industry_keywords = {
            "æ™ºæ…§åŒ»ç–—": ["åŒ»ç–—", "å¥åº·", "è¯Šæ–­", "hospital", "medical", "health"],
            "ä¼ä¸šæœåŠ¡": ["saas", "ä¼ä¸š", "ç®¡ç†ç³»ç»Ÿ", "erp", "crm", "åŠå…¬"],
            "é‡‘èç§‘æŠ€": ["é‡‘è", "æ”¯ä»˜", "è´·æ¬¾", "fintech", "payment", "lending"],
            "æ•™è‚²ç§‘æŠ€": ["æ•™è‚²", "å­¦ä¹ ", "åŸ¹è®­", "education", "learning", "training"],
            "æ™ºèƒ½åˆ¶é€ ": ["åˆ¶é€ ", "å·¥ä¸š", "ç”Ÿäº§", "manufacturing", "industrial", "factory"]
        }
        
        for ind, keywords_list in industry_keywords.items():
            if any(kw in bp_lower for kw in keywords_list):
                industry = ind
                break
        
        # é€šç”¨å…³é”®è¯æ¨¡æ¿
        keywords = [
            f"{industry} å¸‚åœºè§„æ¨¡",
            f"{industry} market size",
            f"{industry} competitors analysis",
            f"{industry} å•†ä¸šæ¨¡å¼",
            f"{industry} business model",
            f"{industry} global trends",
            f"{industry} funding rounds",
            f"{industry} èèµ„åŠ¨æ€",
            f"{industry} leading players",
            f"{industry} è¡Œä¸šæŠ¥å‘Š"
        ]
        
        return {"industry": industry, "keywords": keywords}

    def _concurrent_search(self, keywords: List[str]) -> Dict[str, str]:
        """
        å¹¶å‘æ‰§è¡Œ Google æœç´¢ï¼ˆæ€§èƒ½ä¼˜åŒ–å…³é”®ç‚¹ï¼‰ã€‚
        
        å‚æ•°:
            keywords: æœç´¢å…³é”®è¯åˆ—è¡¨
            
        è¿”å›:
            Dict[å…³é”®è¯, æœç´¢ç»“æœ]
        """
        search_results = {}
        
        def search_worker(kw: str, idx: int):
            """å•ä¸ªæœç´¢ä»»åŠ¡"""
            start_id = idx * 5 + 1  # æ¯ä¸ªå…³é”®è¯æœç´¢ 5 æ¡ï¼ŒID ä¾æ¬¡ç´¯åŠ 
            result = utils.google_search(kw, start_id=start_id)
            return (kw, result)
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = {
                executor.submit(search_worker, kw, i): kw 
                for i, kw in enumerate(keywords)
            }
            
            for future in as_completed(futures):
                kw, result = future.result()
                if result:
                    search_results[kw] = result
        
        logger.info(f"å¹¶å‘æœç´¢å®Œæˆï¼š{len(search_results)}/{len(keywords)} ä¸ªå…³é”®è¯è·å¾—ç»“æœ")
        return search_results

    def _generate_basic_info(self, fusion_context: str) -> Dict:
        """
        ã€å¹¶å‘å­ä»»åŠ¡ 1ã€‘ç”ŸæˆåŸºç¡€ä¿¡æ¯ç»„ï¼šproject_identity, industry_analysis, business_analysis
        
        åŸç†ï¼šè¿™ 3 ä¸ªå­—æ®µä¸»è¦æ¥è‡ª BP å†…å®¹æœ¬èº«ï¼Œæ— éœ€å¤æ‚æ¨ç†ï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆã€‚
        
        å‚æ•°ï¼š
            fusion_context (str): èåˆåçš„ä¸Šä¸‹æ–‡ï¼ˆBP å†…å®¹ + æœç´¢ç»“æœï¼‰
        
        è¿”å›ï¼š
            Dict: åŒ…å« 3 ä¸ªå­—æ®µçš„ JSON å­—å…¸
        """
        try:
            response = self.client.chat.completions.create(
                model=config.LLM_MODEL,
                messages=[
                    {"role": "system", "content": config.PROMPT_IDENTITY_BUSINESS},
                    {"role": "user", "content": fusion_context}
                ],
                temperature=0.3
            )
            raw_output = response.choices[0].message.content
            clean_json = utils.clean_json_string(raw_output)
            # ä½¿ç”¨ repair_json ä¿®å¤å¯èƒ½çš„æˆªæ–­é—®é¢˜
            repaired_json = utils.repair_json(clean_json)
            return json.loads(repaired_json)
        except Exception as e:
            logger.error(f"ç”ŸæˆåŸºç¡€ä¿¡æ¯ç»„å¤±è´¥: {e}")
            return {}

    def _generate_external_intel(self, fusion_context: str) -> Dict:
        """
        ã€å¹¶å‘å­ä»»åŠ¡ 2ã€‘ç”Ÿæˆå¤–éƒ¨æƒ…æŠ¥ç»„ï¼šcompetitors, funding_ecosystem, public_sentiment, raw_evidence
        
        åŸç†ï¼šè¿™ 4 ä¸ªå­—æ®µä¸»è¦åŸºäºè”ç½‘æœç´¢ç»“æœï¼Œå…³æ³¨å¤–éƒ¨å¸‚åœºæƒ…æŠ¥ã€‚
        
        å‚æ•°ï¼š
            fusion_context (str): èåˆåçš„ä¸Šä¸‹æ–‡ï¼ˆBP å†…å®¹ + æœç´¢ç»“æœï¼‰
        
        è¿”å›ï¼š
            Dict: åŒ…å« 4 ä¸ªå­—æ®µçš„ JSON å­—å…¸
        """
        try:
            response = self.client.chat.completions.create(
                model=config.LLM_MODEL,
                messages=[
                    {"role": "system", "content": config.PROMPT_MARKET_COMPETITION},
                    {"role": "user", "content": fusion_context}
                ],
                temperature=0.3
            )
            raw_output = response.choices[0].message.content
            clean_json = utils.clean_json_string(raw_output)
            # ä½¿ç”¨ repair_json ä¿®å¤å¯èƒ½çš„æˆªæ–­é—®é¢˜
            repaired_json = utils.repair_json(clean_json)
            return json.loads(repaired_json)
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤–éƒ¨æƒ…æŠ¥ç»„å¤±è´¥: {e}")
            return {}

    def _generate_valuation(self, fusion_context: str) -> Dict:
        """
        ã€å¹¶å‘å­ä»»åŠ¡ 3ã€‘ç”Ÿæˆä¼°å€¼æ¨¡å‹ï¼švaluation_model
        
        åŸç†ï¼šä¸“æ³¨äºé‡åŒ–è¯„åˆ†ï¼Œå°†å¤æ‚çš„è¯„ä¼°ä»»åŠ¡æ‹†åˆ†ä¸ºç‹¬ç«‹çš„å¹¶å‘ä»»åŠ¡ã€‚
        
        å‚æ•°ï¼š
            fusion_context (str): èåˆåçš„ä¸Šä¸‹æ–‡ï¼ˆBP å†…å®¹ + æœç´¢ç»“æœï¼‰
        
        è¿”å›ï¼š
            Dict: åŒ…å« valuation_model å­—æ®µçš„ JSON å­—å…¸
        """
        try:
            response = self.client.chat.completions.create(
                model=config.LLM_MODEL,
                messages=[
                    {"role": "system", "content": config.PROMPT_VALUATION},
                    {"role": "user", "content": fusion_context}
                ],
                temperature=0.3
            )
            raw_output = response.choices[0].message.content
            clean_json = utils.clean_json_string(raw_output)
            # ä½¿ç”¨ repair_json ä¿®å¤å¯èƒ½çš„æˆªæ–­é—®é¢˜
            repaired_json = utils.repair_json(clean_json)
            return json.loads(repaired_json)
        except Exception as e:
            logger.error(f"ç”Ÿæˆä¼°å€¼æ¨¡å‹å¤±è´¥: {e}")
            return {}

    def _generate_risks_and_qa(self, fusion_context: str) -> Dict:
        """
        ã€å¹¶å‘å­ä»»åŠ¡ 4ã€‘ç”Ÿæˆé£é™©è¯„ä¼°ä¸æ‹·é—®ï¼švc_grill, pain_point_validation, risk_assessment
        
        åŸç†ï¼šä¸“æ³¨äºé£é™©è¯†åˆ«å’Œå°–é”æé—®ï¼Œå‡è½»å•ä¸ªä»»åŠ¡çš„è´Ÿæ‹…ã€‚
        
        å‚æ•°ï¼š
            fusion_context (str): èåˆåçš„ä¸Šä¸‹æ–‡ï¼ˆBP å†…å®¹ + æœç´¢ç»“æœï¼‰
        
        è¿”å›ï¼š
            Dict: åŒ…å« 3 ä¸ªå­—æ®µçš„ JSON å­—å…¸
        """
        try:
            response = self.client.chat.completions.create(
                model=config.LLM_MODEL,
                messages=[
                    {"role": "system", "content": config.PROMPT_RISK_QA},
                    {"role": "user", "content": fusion_context}
                ],
                temperature=0.3
            )
            raw_output = response.choices[0].message.content
            clean_json = utils.clean_json_string(raw_output)
            # ä½¿ç”¨ repair_json ä¿®å¤å¯èƒ½çš„æˆªæ–­é—®é¢˜
            repaired_json = utils.repair_json(clean_json)
            return json.loads(repaired_json)
        except Exception as e:
            logger.error(f"ç”Ÿæˆé£é™©è¯„ä¼°ç»„å¤±è´¥: {e}")
            return {}

    def analyze_bp_pipeline(self, pdf_path: str) -> Dict:
        """
        å…¨æµç¨‹å•†ä¸šåˆ†ææµæ°´çº¿ï¼ˆå‡çº§ç‰ˆï¼šè§†è§‰ä¿¡æ¯å‰ç½®èåˆï¼Œç¡®ä¿å›¾ç‰‡å‹ PDF åˆ†ææœ‰æ•ˆæ€§ï¼‰ã€‚
        
        å‚æ•°:
            pdf_path (str): PDF æ–‡ä»¶è·¯å¾„ã€‚
            
        è¿”å›:
            Dict: æ ¼å¼åŒ–çš„å•†ä¸šåˆ†æ JSON æŠ¥å‘Šã€‚
        """
        try:
            # 1. æ–‡æœ¬ä¸å›¾åƒæå–
            logger.info(f"å¼€å¯æµæ°´çº¿åˆ†æï¼ˆå¤šæ¨¡æ€+å¹¶å‘ä¼˜åŒ–ï¼‰ï¼Œå¤„ç†æ–‡ä»¶: {pdf_path}")
            pdf_content = utils.extract_content_from_pdf(pdf_path)
            bp_full_text = pdf_content["text"]
            bp_images = pdf_content["images"]
            
            if "å¤±è´¥" in bp_full_text:
                return {"error": "PDF å†…å®¹æ— æ³•è¯»å–"}

            # 2. ã€æ­¥éª¤ä¸€ã€‘è§†è§‰åˆ†æï¼ˆç­‰å¾…å®Œæˆä»¥ç¡®ä¿å›¾ç‰‡å‹ PDF è´¨é‡ï¼‰
            visual_descriptions = ""
            if bp_images:
                logger.info(f"æ£€æµ‹åˆ° {len(bp_images)} å¼ æœ‰æ•ˆå›¾ç‰‡ï¼Œæ­£åœ¨æ‰§è¡Œè§†è§‰åˆ†æï¼ˆ3x3 æ‹¼å›¾ä¼˜åŒ–ï¼‰...")
                visual_descriptions = utils.describe_visual_elements(self.vision_client, bp_images)
                logger.info(f"è§†è§‰åˆ†æå®Œæˆï¼Œæå–äº† {len(visual_descriptions)} å­—ç¬¦çš„å›¾è¡¨æè¿°")
            else:
                logger.warning("æœªæ£€æµ‹åˆ°æœ‰æ•ˆå›¾ç‰‡ï¼Œè·³è¿‡è§†è§‰åˆ†æ")

            # 3. ã€æ­¥éª¤äºŒã€‘åˆ›å»ºå¢å¼ºæ–‡æœ¬ï¼ˆèåˆåŸæ–‡æœ¬ä¸è§†è§‰æè¿°ï¼‰
            enhanced_text = bp_full_text
            if visual_descriptions and visual_descriptions != "æœªå‘ç°æ˜¾è‘—è§†è§‰å…ƒç´ ã€‚":
                logger.info("èåˆæ–‡æœ¬ä¸è§†è§‰ä¿¡æ¯ï¼Œç”Ÿæˆå¢å¼ºåˆ†æä¸Šä¸‹æ–‡")
                enhanced_text = f"{bp_full_text}\n\n{visual_descriptions}"
            else:
                logger.warning("æœªè·å–åˆ°æœ‰æ•ˆè§†è§‰å†…å®¹ï¼Œä»…ä½¿ç”¨çº¯æ–‡æœ¬è¿›è¡Œåˆ†æ")

            # 4. ã€æ­¥éª¤ä¸‰ã€‘èµ›é“æ„ŸçŸ¥ä¸å…³é”®è¯ç”Ÿæˆï¼ˆä½¿ç”¨å¢å¼ºæ–‡æœ¬ï¼Œç¡®ä¿è´¨é‡ï¼‰
            logger.info("æ­£åœ¨è¿›è¡Œèµ›é“æ„ŸçŸ¥ä¸å…³é”®è¯ç”Ÿæˆï¼ˆåŸºäºå¢å¼ºæ–‡æœ¬ï¼‰...")
            context_perception = self._perceive_context(enhanced_text)
            detected_industry = context_perception["industry"]
            keywords = context_perception["keywords"]
            logger.info(f"æ„ŸçŸ¥å®Œæˆ - èµ›é“: {detected_industry}, å…³é”®è¯æ•°: {len(keywords)}")
            
            # 5. å¹¶å‘è”ç½‘æ£€ç´¢ï¼ˆæ€§èƒ½ä¼˜åŒ–å…³é”®ç‚¹ï¼‰
            logger.info("æ­£åœ¨å¹¶å‘æ‰§è¡Œ Google æœç´¢...")
            search_results = self._concurrent_search(keywords)
            
            # ç»„è£…æœç´¢ä¸Šä¸‹æ–‡
            search_context = ""
            for kw, result in search_results.items():
                search_context += f"--- å…³é”®è¯: {kw} ---\n{result}\n"

            # 6. å¹¶å‘ JSON ç”Ÿæˆï¼ˆæ€§èƒ½ä¼˜åŒ–å…³é”®ç‚¹ï¼šå°†é•¿æ–‡æœ¬ç”Ÿæˆæ‹†åˆ†ä¸º 4 ä¸ªå­ä»»åŠ¡ï¼‰
            logger.info("å‘èµ·å¹¶å‘ JSON ç”Ÿæˆï¼ˆ4 ä¸ªå­ä»»åŠ¡ï¼‰...")
            bp_summary = enhanced_text[:30000]  # ä½¿ç”¨å¢å¼ºæ–‡æœ¬è€ŒéåŸå§‹æ–‡æœ¬
            fusion_context = (
                f"### ğŸ“„ å•†ä¸šè®¡åˆ’ä¹¦å†…å®¹æ‘˜è¦ï¼ˆåŒ…å«æ–‡æœ¬ä¸å›¾è¡¨è§£æï¼‰\n{bp_summary}\n\n"
                f"### ğŸ” å¤–éƒ¨æœç´¢æƒ…æŠ¥\n{search_context}"
            )
            
            # å¹¶å‘è°ƒç”¨ 4 ä¸ªç”Ÿæˆæ–¹æ³•ï¼ˆMap-Reduce æ¨¡å¼ï¼‰
            result = {}
            with ThreadPoolExecutor(max_workers=4) as executor:
                # æäº¤ 4 ä¸ªå¹¶å‘ä»»åŠ¡
                future_basic = executor.submit(self._generate_basic_info, fusion_context)
                future_intel = executor.submit(self._generate_external_intel, fusion_context)
                future_valuation = executor.submit(self._generate_valuation, fusion_context)
                future_risks = executor.submit(self._generate_risks_and_qa, fusion_context)
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶åˆå¹¶ç»“æœ
                basic_info = future_basic.result()
                external_intel = future_intel.result()
                valuation_data = future_valuation.result()
                risks_qa_data = future_risks.result()
                
                # åˆå¹¶ 4 ä¸ªå­—å…¸
                result.update(basic_info)
                result.update(external_intel)
                result.update(valuation_data)
                result.update(risks_qa_data)
            
            logger.info("å¹¶å‘ JSON ç”Ÿæˆå®Œæˆï¼Œæ­£åœ¨æ ¡éªŒå®Œæ•´æ€§...")

            # 7. JSON å®Œæ•´æ€§æ ¡éªŒä¸å…œåº•ï¼ˆæ–°å¢ valuation_modelï¼‰
            required_keys = ["project_identity", "industry_analysis", "business_analysis", "competitors", "raw_evidence", "vc_grill", "valuation_model", "funding_ecosystem", "pain_point_validation", "public_sentiment", "risk_assessment"]
            for key in required_keys:
                if key not in result:
                    logger.warning(f"å­—æ®µ {key} ç¼ºå¤±ï¼Œæ­£åœ¨è¿›è¡Œé»˜è®¤å¡«å……ã€‚")
                    if key == "project_identity":
                        result[key] = {
                            "project_name": "Unknown Project",
                            "slogan": "N/A",
                            "description": "æœªèƒ½ä» BP ä¸­æå–æ·±åº¦æè¿°",
                            "revenue_model": "N/A",
                            "team_background": "Not Mentioned",
                            "stage": "æœªçŸ¥"
                        }
                    elif key == "industry_analysis":
                        result[key] = {"detected_industry": detected_industry, "market_size": "Not Found", "cagr": "Not Found", "source": "N/A"}
                    elif key == "business_analysis":
                        result[key] = {"business_model_critique": "N/A", "technical_moat": "N/A"}
                    elif key == "competitors": result[key] = []
                    elif key == "raw_evidence": result[key] = []
                    elif key == "vc_grill": result[key] = []
                    elif key == "valuation_model":
                        result[key] = {
                            "total_score": 50,
                            "rating": "C",
                            "summary": "æ•°æ®ä¸¥é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå…¨é¢é‡åŒ–è¯„ä¼°",
                            "dimensions": {
                                "market": {
                                    "score": 10,
                                    "max_score": 20,
                                    "analysis": "ç¼ºä¹å¸‚åœºè§„æ¨¡ä¸å¢é•¿æ•°æ®",
                                    "sub_scores": {"market_size": 5, "timing_growth": 5}
                                },
                                "product": {
                                    "score": 10,
                                    "max_score": 25,
                                    "analysis": "æœªèƒ½è¯†åˆ«æ ¸å¿ƒæŠ€æœ¯å£å’ä¸åˆ›æ–°ç‚¹",
                                    "sub_scores": {"uniqueness": 5, "moat": 5}
                                },
                                "business_model": {
                                    "score": 10,
                                    "max_score": 20,
                                    "analysis": "å•†ä¸šæ¨¡å¼ä¸ç›ˆåˆ©è·¯å¾„ä¸æ˜ç¡®",
                                    "sub_scores": {"profitability": 5, "scalability": 5}
                                },
                                "team": {
                                    "score": 10,
                                    "max_score": 25,
                                    "analysis": "BP ä¸­æœªæåŠæ ¸å¿ƒå›¢é˜ŸèƒŒæ™¯",
                                    "sub_scores": {"founder_capability": 5, "completeness": 5}
                                },
                                "execution": {
                                    "score": 10,
                                    "max_score": 10,
                                    "analysis": "ç¼ºä¹ä¸šåŠ¡éªŒè¯ä¸åˆè§„é£é™©è¯„ä¼°ä¾æ®",
                                    "sub_scores": {"traction": 5, "risk_safety": 5}
                                }
                            }
                        }
                    elif key == "funding_ecosystem": result[key] = {"heat_level": "Unknown", "trend_summary": "Not Found"}
                    elif key == "pain_point_validation": result[key] = {"score": 0, "reason": "N/A"}
                    elif key == "public_sentiment": result[key] = {"label": "Neutral", "summary": "Not Found"}
                    elif key == "risk_assessment": result[key] = ["è¯†åˆ«é£é™©å¤±è´¥"]

            logger.info("åˆ†ææµç¨‹åœ†æ»¡å®Œæˆã€‚")
            return result

        except Exception as e:
            logger.error(f"åˆ†ææµæ°´çº¿å´©æºƒ: {e}\n{traceback.format_exc()}")
            return {
                "error": "Pipeline Failure",
                "details": str(e),
                "template": {
                    "industry_analysis": {"detected_industry": "Error", "market_size": "Not Found", "cagr": "Not Found", "source": "N/A"},
                    "competitors": [],
                    "funding_ecosystem": {"heat_level": "Unknown", "trend_summary": "N/A"},
                    "pain_point_validation": {"score": 0, "reason": "N/A"},
                    "public_sentiment": {"label": "Neutral", "summary": "N/A"},
                    "risk_assessment": ["å†…éƒ¨ç³»ç»Ÿå¼‚å¸¸"]
                }
            }
