"""
agent.py
å•†ä¸šåˆ†ææ™ºèƒ½ä½“æ ¸å¿ƒæ¨¡å—ã€‚
è´Ÿè´£åè°ƒ PDF è§£æã€èµ›é“è¯†åˆ«ã€è”ç½‘æœç´¢åŠå…¨é¢†åŸŸ VC è§†è§’æ·±åº¦åˆ†æã€‚
"""

import json
import logging
import traceback
from typing import List, Dict
from openai import OpenAI
import config
import utils

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class BusinessResearcher:
    """
    å•†ä¸šç ”ç©¶å‘˜æ™ºèƒ½ä½“ï¼Œæ¨¡æ‹Ÿ VC åˆä¼™äººè¿›è¡Œé¡¹ç›®è¯„å®¡ã€‚
    """

    def __init__(self, api_key: str):
        """
        åˆå§‹åŒ–æ™ºèƒ½ä½“ã€‚
        
        å‚æ•°:
            api_key (str): LLM æˆæƒå¯†é’¥ã€‚
        """
        self.api_key = api_key
        self.client = OpenAI(
            api_key=api_key,
            base_url=config.LLM_BASE_URL
        )
        
        # è§†è§‰ä¸“ç”¨å®¢æˆ·ç«¯ (è§£å†³ 400 é”™è¯¯ï¼šè§£è€¦å¤šæ¨¡æ€ä¸æ–‡æœ¬è¯·æ±‚)
        vision_api_key = getattr(config, "VISION_API_KEY", api_key)
        vision_base_url = getattr(config, "VISION_BASE_URL", config.LLM_BASE_URL)
        
        # å¦‚æœè§†è§‰é…ç½®ä¸æ–‡æœ¬é…ç½®ä¸€è‡´ä¸”ä¸º DeepSeekï¼Œåˆ™ä¼šæœ‰å…¼å®¹æ€§é£é™©
        # å»ºè®®ç”¨æˆ·åœ¨ config.py ä¸­æ˜ç¡®é…ç½® VISION_BASE_URL ä¸ºæ”¯æŒ Vision çš„ç«¯ç‚¹
        self.vision_client = OpenAI(
            api_key=vision_api_key,
            base_url=vision_base_url,
            timeout=120.0  # å¢åŠ è¶…æ—¶é™åˆ¶ï¼Œé€‚åº”ä»£ç†ç¯å¢ƒä¸‹çš„å›¾ç‰‡ä¸Šä¼ 
        )

    def _detect_industry(self, bp_text: str) -> str:
        """
        ç¬¬ä¸€é˜¶æ®µï¼šè¯†åˆ«é¡¹ç›®ç»†åˆ†èµ›é“ã€‚
        
        å‚æ•°:
            bp_text (str): BP å…¨æ–‡ï¼ˆå¯åŒ…å«å›¾è¡¨æè¿°çš„å¢å¼ºæ–‡æœ¬ï¼‰ã€‚
            
        è¿”å›:
            str: è¯†åˆ«å‡ºçš„èµ›é“åç§°ã€‚
        """
        bp_snippet = bp_text[:20000]
        prompt = (
            "ä½ æ˜¯ä¸€åå…¨é¢†åŸŸ VC åˆä¼™äººï¼Œæ“…é•¿å¿«é€Ÿè¯†åˆ«åˆ›ä¸šé¡¹ç›®æ‰€å±çš„ç»†åˆ†èµ›é“ã€‚\n\n"
            "### ä»»åŠ¡\n"
            "é˜…è¯»ä»¥ä¸‹å•†ä¸šè®¡åˆ’ä¹¦æ‘˜è¦ï¼Œè¯†åˆ«è¯¥é¡¹ç›®å±äºå“ªä¸ª**ç»†åˆ†èµ›é“**ã€‚\n\n"
            "### è¾“å‡ºæ ¼å¼\n"
            "ç”¨ 'å¤§èµ›é“ - å°èµ›é“' çš„æ ¼å¼è¿”å›ï¼Œå¦‚ï¼š'æ™ºæ…§åŒ»ç–— - AI è¾…åŠ©è¯Šæ–­'ã€‚\n"
            "ä»…è¿”å›èµ›é“åç§°ï¼Œä¸è¦è¯´åºŸè¯ã€‚\n\n"
            f"å•†ä¸šè®¡åˆ’ä¹¦æ‘˜è¦ï¼š\n{bp_snippet}"
        )
        
        try:
            response = self.client.chat.completions.create(
                model=config.LLM_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2
            )
            industry = response.choices[0].message.content.strip()
            logger.info(f"è¯†åˆ«åˆ°èµ›é“: {industry}")
            return industry
        except Exception as e:
            logger.error(f"èµ›é“è¯†åˆ«å¤±è´¥: {e}")
            return "å…¨é¢†åŸŸèµ›é“"

    def _get_search_keywords(self, bp_text: str, detected_industry: str) -> List[str]:
        """
        ç¬¬äºŒé˜¶æ®µï¼šåŸºäºèµ›é“ç”Ÿæˆä¸­è‹±æ–‡åŒè¯­æœç´¢å…³é”®è¯ã€‚
        
        å‚æ•°:
            bp_text (str): BP æ–‡æœ¬ï¼ˆå¯åŒ…å«å›¾è¡¨æè¿°çš„å¢å¼ºæ–‡æœ¬ï¼‰ã€‚
            detected_industry (str): è¯†åˆ«å‡ºçš„èµ›é“ã€‚
        """
        bp_snippet = bp_text[:30000]
        prompt = (
            "ä½ æ˜¯ä¸€åèµ„æ·±çš„å•†ä¸šæƒ…æŠ¥åˆ†æå¸ˆï¼Œæ“…é•¿ä»å•†ä¸šè®¡åˆ’ä¹¦ä¸­æå–é«˜è´¨é‡çš„ä¸­è‹±æ–‡åŒè¯­æœç´¢å…³é”®è¯ã€‚\n\n"
            f"é¡¹ç›®èµ›é“ï¼š**{detected_industry}**\n"
            "### ä»»åŠ¡\n"
            "æå– 10 ä¸ªç²¾å‡†æœç´¢å…³é”®è¯ï¼ˆ5 ä¸ªä¸­æ–‡ï¼Œ5 ä¸ªè‹±æ–‡ï¼‰ï¼Œç”¨äºåœ¨ Google æŸ¥æ‰¾å…¨çƒå¸‚åœºæ•°æ®ã€å›½é™…ç«å“å’Œå•†ä¸šæ¨¡å¼è¶‹åŠ¿ã€‚\n\n"
            "### ç­–ç•¥è¦æ±‚ï¼š\n"
            "1. **ä¸­æ–‡å…³é”®è¯**ï¼šè¦†ç›–å›½å†…å¸‚åœºè§„æ¨¡ã€æ”¿ç­–ç¯å¢ƒã€æœ¬åœŸç«å“åˆ†æã€‚\n"
            "2. **è‹±æ–‡å…³é”®è¯**ï¼šè¦†ç›–å…¨çƒè¡Œä¸šæŠ¥å‘Šï¼ˆGlobal Market Reportï¼‰ã€æµ·å¤–å·¨å¤´åŠ¨æ€ï¼ˆLeading Playersï¼‰ã€å›½é™…èèµ„è¶‹åŠ¿ï¼ˆFunding Trendsï¼‰ã€‚\n"
            "3. **å¿…é¡»åŒ…å«æ¨¡å¼å˜ä½“**ï¼šä¾‹å¦‚ \"{Industry} market size\"ã€\"{Competitor} revenue\"ã€\"{Industry} failure cases\"ã€‚\n\n"
            "### è¾“å‡ºæ ¼å¼\n"
            "ä»…è¿”å›å…³é”®è¯ï¼Œç”¨è‹±æ–‡é€—å·åˆ†éš”ã€‚ä¸è¦æœ‰ä»»ä½•è§£é‡Šã€‚\n\n"
            f"å•†ä¸šè®¡åˆ’ä¹¦ç‰‡æ®µï¼š\n{bp_snippet}"
        )
        
        try:
            response = self.client.chat.completions.create(
                model=config.LLM_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            keywords_text = response.choices[0].message.content.strip()
            keywords = [k.strip() for k in keywords_text.split(',')]
            return keywords[:10]
        except Exception as e:
            logger.error(f"æå–åŒè¯­å…³é”®è¯å¤±è´¥: {e}")
            return [
                f"{detected_industry} å¸‚åœºè§„æ¨¡", 
                f"{detected_industry} market size",
                f"{detected_industry} competitors analysis",
                f"{detected_industry} å•†ä¸šæ¨¡å¼",
                f"{detected_industry} business model",
                f"{detected_industry} global trends"
            ]

    def analyze_bp_pipeline(self, pdf_path: str) -> Dict:
        """
        å…¨æµç¨‹å•†ä¸šåˆ†ææµæ°´çº¿ï¼ˆå‡çº§ç‰ˆï¼šè§†è§‰ä¿¡æ¯å‰ç½®èåˆï¼Œç¡®ä¿å›¾ç‰‡å‹ PDF åˆ†ææœ‰æ•ˆæ€§ï¼‰ã€‚
        
        å‚æ•°:
            pdf_path (str): PDF æ–‡ä»¶è·¯å¾„ã€‚
            
        è¿”å›:
            Dict: æ ¼å¼åŒ–çš„å•†ä¸šåˆ†æ JSON æŠ¥å‘Šã€‚
        """
        try:
            # 1. æ–‡æœ¬ä¸å›¾åƒæå–
            logger.info(f"å¼€å¯æµæ°´çº¿åˆ†æï¼ˆå¤šæ¨¡æ€ï¼‰ï¼Œå¤„ç†æ–‡ä»¶: {pdf_path}")
            pdf_content = utils.extract_content_from_pdf(pdf_path)
            bp_full_text = pdf_content["text"]
            bp_images = pdf_content["images"]
            
            if "å¤±è´¥" in bp_full_text:
                return {"error": "PDF å†…å®¹æ— æ³•è¯»å–"}

            # 2. è§†è§‰å†…å®¹è§£æï¼ˆå‰ç½®åˆ°èµ›é“è¯†åˆ«ä¹‹å‰ï¼Œå…³é”®ä¿®å¤ç‚¹ï¼‰
            visual_descriptions = ""
            if bp_images:
                logger.info(f"æ£€æµ‹åˆ° {len(bp_images)} å¼ æœ‰æ•ˆå›¾ç‰‡ï¼Œæ­£åœ¨å‘èµ·è§†è§‰åˆ†æ...")
                visual_descriptions = utils.describe_visual_elements(self.vision_client, bp_images)
                logger.info(f"è§†è§‰åˆ†æå®Œæˆï¼Œæå–äº† {len(visual_descriptions)} å­—ç¬¦çš„å›¾è¡¨æè¿°")

            # 2.5 åˆ›å»ºå¢å¼ºæ–‡æœ¬ï¼ˆæ ¸å¿ƒä¿®å¤ï¼šèåˆåŸæ–‡æœ¬ä¸è§†è§‰æè¿°ï¼‰
            enhanced_text = bp_full_text
            if visual_descriptions and visual_descriptions != "æœªå‘ç°æ˜¾è‘—è§†è§‰å…ƒç´ ã€‚":
                logger.info("æ­£åœ¨èåˆæ–‡æœ¬ä¸è§†è§‰ä¿¡æ¯ï¼Œç”Ÿæˆå¢å¼ºåˆ†æä¸Šä¸‹æ–‡...")
                enhanced_text = f"{bp_full_text}\n\n{visual_descriptions}"
            else:
                logger.warning("æœªæ£€æµ‹åˆ°æœ‰æ•ˆè§†è§‰å†…å®¹ï¼Œä»…ä½¿ç”¨çº¯æ–‡æœ¬è¿›è¡Œåˆ†æ")

            # 3. èµ›é“æ„ŸçŸ¥ï¼ˆç°åœ¨åŸºäºå¢å¼ºæ–‡æœ¬ï¼Œå›¾ç‰‡å‹ PDF ä¹Ÿèƒ½å‡†ç¡®è¯†åˆ«ï¼‰
            detected_industry = self._detect_industry(enhanced_text)
            
            # 4. å…³é”®è¯è·å–ï¼ˆç°åœ¨åŸºäºå¢å¼ºæ–‡æœ¬ï¼Œå…³é”®è¯æ›´ç²¾å‡†ï¼‰
            keywords = self._get_search_keywords(enhanced_text, detected_industry)
            
            # 5. è”ç½‘æ£€ç´¢
            search_context = ""
            current_id = 1
            for kw in keywords:
                result = utils.google_search(kw, start_id=current_id)
                if result:
                    search_context += f"--- å…³é”®è¯: {kw} ---\n{result}\n"
                    # æ›´æ–°ä¸‹ä¸€ä¸ªå…³é”®è¯çš„èµ·å§‹ ID
                    current_id += result.count("[S")

            # 6. LLM æ·±åº¦åˆ†æï¼ˆèåˆæ–‡æœ¬ã€è§†è§‰ä¸æœç´¢æƒ…æŠ¥ï¼‰
            logger.info("å‘èµ· LLM æ·±åº¦èåˆåˆ†æ...")
            bp_summary = enhanced_text[:30000]  # ä½¿ç”¨å¢å¼ºæ–‡æœ¬è€ŒéåŸå§‹æ–‡æœ¬
            fusion_context = (
                f"### ğŸ“„ å•†ä¸šè®¡åˆ’ä¹¦å†…å®¹æ‘˜è¦ï¼ˆåŒ…å«æ–‡æœ¬ä¸å›¾è¡¨è§£æï¼‰\n{bp_summary}\n\n"
                f"### ğŸ” å¤–éƒ¨æœç´¢æƒ…æŠ¥\n{search_context}"
            )
            
            messages = [
                {"role": "system", "content": config.SYSTEM_PROMPT},
                {"role": "user", "content": fusion_context}
            ]
            
            response = self.client.chat.completions.create(
                model=config.LLM_MODEL,
                messages=messages,
                temperature=0.5
            )
            
            raw_output = response.choices[0].message.content
            clean_json = utils.clean_json_string(raw_output)
            result = json.loads(clean_json)

            # 7. JSON å®Œæ•´æ€§æ ¡éªŒä¸å…œåº•
            required_keys = ["project_identity", "industry_analysis", "business_analysis", "competitors", "raw_evidence", "vc_grill", "funding_ecosystem", "pain_point_validation", "public_sentiment", "risk_assessment"]
            for key in required_keys:
                if key not in result:
                    logger.warning(f"å­—æ®µ {key} ç¼ºå¤±ï¼Œæ­£åœ¨è¿›è¡Œé»˜è®¤å¡«å……ã€‚")
                    if key == "project_identity":
                        result[key] = {
                            "project_name": "Unknown Project",
                            "slogan": "N/A",
                            "description": "æœªèƒ½ä» BP ä¸­æå–æ·±åº¦æè¿°",
                            "revenue_model": "N/A",
                            "team_background": "Not Mentioned",
                            "stage": "æœªçŸ¥"
                        }
                    elif key == "industry_analysis":
                        result[key] = {"detected_industry": detected_industry, "market_size": "Not Found", "cagr": "Not Found", "source": "N/A"}
                    elif key == "business_analysis":
                        result[key] = {"business_model_critique": "N/A", "technical_moat": "N/A"}
                    elif key == "competitors": result[key] = []
                    elif key == "raw_evidence": result[key] = []
                    elif key == "vc_grill": result[key] = []
                    elif key == "funding_ecosystem": result[key] = {"heat_level": "Unknown", "trend_summary": "Not Found"}
                    elif key == "pain_point_validation": result[key] = {"score": 0, "reason": "N/A"}
                    elif key == "public_sentiment": result[key] = {"label": "Neutral", "summary": "Not Found"}
                    elif key == "risk_assessment": result[key] = ["è¯†åˆ«é£é™©å¤±è´¥"]

            logger.info("åˆ†ææµç¨‹åœ†æ»¡å®Œæˆã€‚")
            return result

        except Exception as e:
            logger.error(f"åˆ†ææµæ°´çº¿å´©æºƒ: {e}\n{traceback.format_exc()}")
            return {
                "error": "Pipeline Failure",
                "details": str(e),
                "template": {
                    "industry_analysis": {"detected_industry": "Error", "market_size": "Not Found", "cagr": "Not Found", "source": "N/A"},
                    "competitors": [],
                    "funding_ecosystem": {"heat_level": "Unknown", "trend_summary": "N/A"},
                    "pain_point_validation": {"score": 0, "reason": "N/A"},
                    "public_sentiment": {"label": "Neutral", "summary": "N/A"},
                    "risk_assessment": ["å†…éƒ¨ç³»ç»Ÿå¼‚å¸¸"]
                }
            }
